I"Év<p><br /></p>
<h4>Readings</h4>
<p><a href="https://machinelearningmastery.com/feature-selection-machine-learning-python/">
https://machinelearningmastery.com/feature-selection-machine-learning-python/
</a><br />
<a href="https://scikit-learn.org/stable/modules/feature_selection.html">
https://scikit-learn.org/stable/modules/feature_selection.html
</a></p>

<p><br /></p>
<h4>Libraries</h4>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">import</span> <span class="n">matplotlib</span><span class="p">.</span><span class="nf">pyplot</span> <span class="n">as</span> <span class="n">plt</span>
<span class="n">import</span> <span class="n">pandas</span> <span class="n">as</span> <span class="n">pd</span>
<span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">seaborn</span> <span class="n">as</span> <span class="n">sns</span>
<span class="n">import</span> <span class="n">statsmodels</span><span class="p">.</span><span class="nf">api</span> <span class="n">as</span> <span class="n">sm</span>

<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">preprocessing</span> <span class="n">import</span> <span class="no">StandardScaler</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">linear_model</span> <span class="n">import</span> <span class="no">LogisticRegression</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">feature_selection</span> <span class="n">import</span> <span class="no">RFE</span><span class="p">,</span> <span class="no">SelectKBest</span><span class="p">,</span> <span class="n">f_regression</span><span class="p">,</span> <span class="no">VarianceThreshold</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">model_selection</span> <span class="n">import</span> <span class="n">train_test_split</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">ensemble</span> <span class="n">import</span> <span class="no">ExtraTreesClassifier</span><span class="p">,</span> <span class="no">RandomForestClassifier</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">metrics</span> <span class="n">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>

<span class="n">import</span> <span class="n">tensorflow</span> <span class="n">as</span> <span class="n">tf</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span></code></pre></figure>

<p><br /></p>
<h4>Get Data</h4>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">datasets</span> <span class="n">import</span> <span class="n">load_breast_cancer</span>

<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cancer</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'target names '</span><span class="p">,</span> <span class="n">cancer</span><span class="p">[</span><span class="s1">'target_names'</span><span class="p">])</span>
<span class="c1"># print(cancer['DESCR'])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">DataFrame</span><span class="p">(</span><span class="n">cancer</span><span class="p">[</span><span class="s1">'data'</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="n">cancer</span><span class="p">[</span><span class="s1">'feature_names'</span><span class="p">])</span>
<span class="n">features_for_pca</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">columns</span><span class="p">.</span><span class="nf">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="s1">'target'</span><span class="p">)[</span><span class="s1">'target'</span><span class="p">].</span><span class="nf">count</span><span class="p">())</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="no">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">scaled_data</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Replace spaces</span>
<span class="n">column_names</span>  <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="nb">name</span> <span class="k">in</span> <span class="n">df</span><span class="p">.</span><span class="nf">columns</span><span class="p">:</span>
    <span class="n">column_names</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nb">name</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"_"</span><span class="p">))</span> <span class="c1">#_ Added for Atom</span>

<span class="n">df</span><span class="p">.</span><span class="nf">columns</span> <span class="o">=</span> <span class="n">column_names</span>
<span class="c1"># print(df.columns)</span>

<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span></code></pre></figure>

<p><br /></p>
<h4>Logistic Regression L1</h4>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="no">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">'l1'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">coef_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">coef</span><span class="p">,</span> <span class="n">feat</span> <span class="k">in</span> <span class="n">zip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="no">X</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">coef</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span> <span class="n">coef_dict</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="no">DataFrame</span><span class="p">.</span><span class="nf">from_dict</span><span class="p">(</span><span class="n">coef_dict</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">'index'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Coef'</span><span class="p">]).</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">'Coef'</span><span class="p">]))</span>

<span class="c1"># or</span>

<span class="n">vth</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">DataFrame</span><span class="p">({</span>
                    <span class="s1">'Name'</span><span class="p">:</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">columns</span><span class="p">,</span>
                    <span class="s1">'VThScore'</span><span class="p">:</span> <span class="n">model</span><span class="p">.</span><span class="nf">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                   <span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vth</span><span class="p">[</span><span class="n">vth</span><span class="p">[</span><span class="s1">'VThScore'</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">].</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">'VThScore'</span><span class="p">])</span><span class="o">.</span><span class="no">Name</span><span class="p">)</span></code></pre></figure>

<p><br /></p>
<h4>VarianceThreshold</h4>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">sel</span> <span class="o">=</span> <span class="no">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="p">(</span><span class="o">.</span><span class="mi">8</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="o">.</span><span class="mi">8</span><span class="p">)))</span>
<span class="n">sel</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="no">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="nf">columns</span><span class="p">[</span><span class="n">sel</span><span class="p">.</span><span class="nf">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="no">True</span><span class="p">)]].</span><span class="nf">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Coef'</span><span class="p">]))</span></code></pre></figure>

<p><br /></p>
<h4>SelectKBest</h4>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span>

<span class="n">selector</span> <span class="o">=</span> <span class="no">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fit_skb</span> <span class="o">=</span> <span class="n">selector</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">skb</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">DataFrame</span><span class="p">({</span>
                    <span class="s1">'Name'</span><span class="p">:</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">columns</span><span class="p">,</span>
                    <span class="s1">'SKBScore'</span><span class="p">:</span> <span class="n">fit_skb</span><span class="p">.</span><span class="nf">scores_</span>
                   <span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="n">skb</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">'SKBScore'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="no">False</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

<span class="c1"># cols = selector.get_support(indices=True)</span>
<span class="c1"># print(cols)</span>
<span class="c1"># print(df.columns[cols])</span></code></pre></figure>

<p><br /></p>
<h4>Recursive Feature Elimination</h4>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">model</span> <span class="o">=</span> <span class="no">LogisticRegression</span><span class="p">()</span>
<span class="n">rfe</span> <span class="o">=</span> <span class="no">RFE</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">rfe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">DataFrame</span><span class="p">({</span>
                    <span class="s1">'Name'</span><span class="p">:</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">columns</span><span class="p">,</span>
                    <span class="s1">'Rank'</span><span class="p">:</span> <span class="n">fit</span><span class="p">.</span><span class="nf">ranking_</span><span class="p">,</span>
                    <span class="s1">'Support'</span><span class="p">:</span> <span class="n">fit</span><span class="p">.</span><span class="nf">support_</span>
                   <span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="n">rfe</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">'Rank'</span><span class="p">]).</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">())</span></code></pre></figure>

<p><br /></p>
<h4>Extra Trees</h4>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">extrees</span> <span class="o">=</span> <span class="no">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">extrees</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">extrees</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">DataFrame</span><span class="p">({</span>
                    <span class="s1">'Name'</span><span class="p">:</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">columns</span><span class="p">,</span>
                    <span class="s1">'ExTrees'</span><span class="p">:</span> <span class="n">extrees</span><span class="p">.</span><span class="nf">feature_importances_</span>                    
                   <span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="n">extrees</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">'ExTrees'</span><span class="p">]).</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">())</span></code></pre></figure>

<p><br />
Hat tip to
<a href="https://www.udemy.com/user/soledad-galli/">
Soledad Galli
</a> onward
<br /><br />
In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit.</p>

<h4>Misc Methods</h4>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># remove constant features</span>
<span class="n">constant_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">feat</span> <span class="k">for</span> <span class="n">feat</span> <span class="k">in</span> <span class="no">X_train</span><span class="p">.</span><span class="nf">columns</span> <span class="k">if</span> <span class="no">X_train</span><span class="p">[</span><span class="n">feat</span><span class="p">].</span><span class="nf">std</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
<span class="p">]</span>

<span class="no">X_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">constant_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>
<span class="no">X_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">constant_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

<span class="no">X_train</span><span class="p">.</span><span class="nf">shape</span><span class="p">,</span> <span class="no">X_test</span><span class="p">.</span><span class="nf">shape</span>

<span class="c1"># remove quasi-constant features</span>
<span class="n">sel</span> <span class="o">=</span> <span class="no">VarianceThreshold</span><span class="p">(</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>  <span class="c1"># 0.1 indicates 99% of observations approximately</span>

<span class="n">sel</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X_train</span><span class="p">)</span>  <span class="c1"># fit finds the features with low variance</span>

<span class="n">sum</span><span class="p">(</span><span class="n">sel</span><span class="p">.</span><span class="nf">get_support</span><span class="p">())</span>

<span class="c1"># check for duplicated features in the training set</span>
<span class="n">duplicated_feat</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">len</span><span class="p">(</span><span class="no">X_train</span><span class="p">.</span><span class="nf">columns</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># this helps me understand how the loop is going</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="n">col_1</span> <span class="o">=</span> <span class="no">X_train</span><span class="p">.</span><span class="nf">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">col_2</span> <span class="k">in</span> <span class="no">X_train</span><span class="p">.</span><span class="nf">columns</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]:</span>
        <span class="k">if</span> <span class="no">X_train</span><span class="p">[</span><span class="n">col_1</span><span class="p">].</span><span class="nf">equals</span><span class="p">(</span><span class="no">X_train</span><span class="p">[</span><span class="n">col_2</span><span class="p">]):</span>
            <span class="n">duplicated_feat</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">col_2</span><span class="p">)</span>

<span class="n">len</span><span class="p">(</span><span class="n">duplicated_feat</span><span class="p">)</span>

<span class="c1"># remove duplicated features</span>
<span class="no">X_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">duplicated_feat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>
<span class="no">X_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">duplicated_feat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

<span class="no">X_train</span><span class="p">.</span><span class="nf">shape</span><span class="p">,</span> <span class="no">X_test</span><span class="p">.</span><span class="nf">shape</span>

<span class="c1"># find and remove correlated features</span>
<span class="c1"># to reduce the feature space</span>

<span class="k">def</span> <span class="nf">correlation</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="n">col_corr</span> <span class="o">=</span> <span class="n">set</span><span class="p">()</span>  <span class="c1"># Set of all the names of correlated columns</span>
    <span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">corr</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">.</span><span class="nf">columns</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">abs</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">.</span><span class="nf">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">&gt;</span> <span class="ss">threshold: </span><span class="c1"># we are interested in absolute coeff value</span>
                <span class="n">colname</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="p">.</span><span class="nf">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>  <span class="c1"># getting the name of column</span>
                <span class="n">col_corr</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">col_corr</span>

<span class="n">corr_features</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="no">X_train</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>

<span class="c1"># removed correlated  features</span>
<span class="no">X_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">corr_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>
<span class="no">X_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">corr_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

<span class="no">X_train</span><span class="p">.</span><span class="nf">shape</span><span class="p">,</span> <span class="no">X_test</span><span class="p">.</span><span class="nf">shape</span>

<span class="c1"># from sklearn.model_selection import train_test_split</span>
<span class="c1"># from sklearn.metrics import roc_auc_score</span>
<span class="c1"># from mlxtend.feature_selection import SequentialFeatureSelector as SFS</span>

<span class="c1"># Step backward greedy selection algorithm</span>

<span class="c1"># sfs1 = SFS(RandomForestRegressor(),</span>
<span class="c1">#            k_features=10,</span>
<span class="c1">#            forward=False,</span>
<span class="c1">#            floating=False,</span>
<span class="c1">#            verbose=2,</span>
<span class="c1">#            scoring='r2',</span>
<span class="c1">#            cv=3)</span>

<span class="c1"># sfs1 = sfs1.fit(np.array(X_train), y_train)</span>

<span class="c1"># Exhaustive feature selector</span>

<span class="c1"># from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS</span>

<span class="c1"># efs1 = EFS(RandomForestClassifier(n_jobs=4, random_state=0),</span>
<span class="c1">#            min_features=1,</span>
<span class="c1">#            max_features=4,</span>
<span class="c1">#            scoring='roc_auc',</span>
<span class="c1">#            print_progress=True,</span>
<span class="c1">#            cv=2)</span>

<span class="c1"># efs1 = efs1.fit(np.array(X_train[X_train.columns[0:4]].fillna(0)), y_train)</span>

<span class="c1"># find important features using univariate roc-auc</span>

<span class="c1"># select features using the coefficient of a non</span>
<span class="c1"># regularised logistic regression</span>

<span class="c1"># from sklearn.feature_selection import SelectFromModel</span>
<span class="c1"># https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html</span>

<span class="c1"># sfm = SelectFromModel(LogisticRegression(C=1000))</span>
<span class="c1"># sfm.fit(scaler.transform(X, y)</span>

<span class="c1"># SelectFromModel(RandomForestClassifier(n_estimators=400))</span></code></pre></figure>

:ET